resources:
  jobs:
    Generate_NHP_Data_Inputs:
      name: Generate NHP Data (Inputs)
      webhook_notifications:
        on_success:
          - id: 11be34cb-f1f0-42ca-99d8-e7b3e75e20ca
        on_failure:
          - id: 11be34cb-f1f0-42ca-99d8-e7b3e75e20ca
      tasks:
        - task_key: run_inputs_data
          condition_task:
            op: EQUAL_TO
            left: "{{job.parameters.run_inputs_data}}"
            right: "True"
        - task_key: helpers
          depends_on:
            - task_key: run_inputs_data
              outcome: "true"
          spark_python_task:
            python_file: inputs_data/helpers.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: catchments
          depends_on:
            - task_key: helpers
          spark_python_task:
            python_file: inputs_data/catchments.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_age_sex
          depends_on:
            - task_key: catchments
          spark_python_task:
            python_file: inputs_data/age_sex.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_baseline
          depends_on:
            - task_key: extract_age_sex
          spark_python_task:
            python_file: inputs_data/baseline.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_covid_adjustment
          depends_on:
            - task_key: extract_baseline
          spark_python_task:
            python_file: inputs_data/covid_adjustment.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_diagnoses
          depends_on:
            - task_key: extract_covid_adjustment
          spark_python_task:
            python_file: inputs_data/diagnoses.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_expat_repat
          depends_on:
            - task_key: extract_diagnoses
          spark_python_task:
            python_file: inputs_data/expat_repat.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_procedures
          depends_on:
            - task_key: extract_expat_repat
          spark_python_task:
            python_file: inputs_data/procedures.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_rates
          depends_on:
            - task_key: extract_procedures
          spark_python_task:
            python_file: inputs_data/rates.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_wli
          depends_on:
            - task_key: extract_rates
          spark_python_task:
            python_file: inputs_data/wli.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
        - task_key: extract_inequalities
          depends_on:
            - task_key: extract_wli
          spark_python_task:
            python_file: inputs_data/inequalities.py
            parameters:
              - "{{job.parameters.save_path}}"
            source: GIT
          job_cluster_key: nhp_inputs_data_extract
      job_clusters:
        - job_cluster_key: nhp_inputs_data_extract
          new_cluster:
            cluster_name: ""
            spark_version: 15.4.x-scala2.12
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            instance_pool_id: 0129-130615-maw351-pool-pss8mvfy
            data_security_mode: SINGLE_USER
            runtime_engine: PHOTON
            autoscale:
              min_workers: 2
              max_workers: 8
      git_source:
        git_url: https://github.com/The-Strategy-Unit/nhp_data.git
        git_provider: gitHub
        git_branch: main
      tags:
        group: nhp_data
      queue:
        enabled: true
      parameters:
        - name: run_inputs_data
          default: "True"
        - name: save_path
          default: /Volumes/nhp/inputs_data/files/dev
